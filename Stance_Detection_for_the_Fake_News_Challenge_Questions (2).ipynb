{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stance_Detection_for_the_Fake_News_Challenge_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI9jhXKPCFcJ",
        "colab_type": "text"
      },
      "source": [
        "# Stance Detection for the Fake News Challenge\n",
        "\n",
        "## Identifying Textual Relationships with Deep Neural Nets\n",
        "\n",
        "### Check the problem context [here](https://drive.google.com/open?id=1KfWaZyQdGBw8AUTacJ2yY86Yxgw2Xwq0).\n",
        "\n",
        "### Download files required for the project from [here](https://drive.google.com/open?id=10yf39ifEwVihw4xeJJR60oeFBY30Y5J8)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSNgdEMpenpE",
        "colab_type": "text"
      },
      "source": [
        "## Step1: Load the given dataset  \n",
        "\n",
        "1. Mount the google drive\n",
        "\n",
        "2. Import Glove embeddings\n",
        "\n",
        "3. Import the test and train datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPOZRohMiSpQ",
        "colab_type": "text"
      },
      "source": [
        "### Mount the google drive to access required project files\n",
        "\n",
        "Run the below commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AS39z1XgFpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_7yCFdzgFsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "1e660d59-ed0d-4825-b4f2-97d5f14cdaa2"
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhZdJ4zpwWzN",
        "colab_type": "text"
      },
      "source": [
        "#### Path for Project files on google drive\n",
        "\n",
        "**Note:** You need to change this path according where you have kept the files in google drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aol97RUogFuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/NLP/Sequence NLP/Fake News Challenge/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ly0VxAnwJ2f",
        "colab_type": "text"
      },
      "source": [
        "### Loading the Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmsPn6PF-cgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'glove.6B.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjLJEQ_PwcGi",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset [5 Marks]\n",
        "\n",
        "1. Using [read_csv()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) in pandas load the given train datasets files **`train_bodies.csv`** and **`train_stances.csv`**\n",
        "\n",
        "2. Using [merge](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) command in pandas merge the two datasets based on the Body ID. \n",
        "\n",
        "Note: Save the final merged dataset in a dataframe with name **`dataset`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWRXO4N00i6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gXO1WZ-gFwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bodies_df = pd.read_csv(project_path + 'train_bodies.csv')\n",
        "train_stances_df = pd.read_csv(project_path + 'train_stances.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kosAWskdOOT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "4709ec8a-f02a-40e0-b90b-3a6047724816"
      },
      "source": [
        "train_bodies_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>Posting photos of a gun-toting child online, I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID                                        articleBody\n",
              "0        0  A small meteorite crashed into a wooded area i...\n",
              "1        4  Last week we hinted at what was to come as Ebo...\n",
              "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
              "3        6  Posting photos of a gun-toting child online, I...\n",
              "4        7  At least 25 suspected Boko Haram insurgents we..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qT0Fmtj087W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f47f961e-bc23-453d-9d55-17bcfe4bc58d"
      },
      "source": [
        "train_stances_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Police find mass graves with at least '15 bodi...</td>\n",
              "      <td>712</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
              "      <td>158</td>\n",
              "      <td>agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
              "      <td>137</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
              "      <td>1034</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
              "      <td>1923</td>\n",
              "      <td>disagree</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  Body ID     Stance\n",
              "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
              "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
              "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
              "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
              "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMb4Wb5D8kPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_merge_df = pd.merge(train_bodies_df, train_stances_df, on=\"Body ID\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scIYBm1_85EK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "e51c1bac-368e-48d3-d9d5-4dca155d5220"
      },
      "source": [
        "train_merge_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ...     Stance\n",
              "0        0  ...  unrelated\n",
              "1        0  ...  unrelated\n",
              "2        0  ...  unrelated\n",
              "3        0  ...  unrelated\n",
              "4        0  ...  unrelated\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ycQbBCg20S",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<h2> Check1:</h2>\n",
        "  \n",
        "<h3> You should see the below output if you run `dataset.head()` command as given below </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f78f6146-e7b4-49c7-e8f2-c33b4611c08d",
        "id": "Fy4Ng9K0Kopv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID                                        articleBody  \\\n",
              "0        0  A small meteorite crashed into a wooded area i...   \n",
              "1        0  A small meteorite crashed into a wooded area i...   \n",
              "2        0  A small meteorite crashed into a wooded area i...   \n",
              "3        0  A small meteorite crashed into a wooded area i...   \n",
              "4        0  A small meteorite crashed into a wooded area i...   \n",
              "\n",
              "                                            Headline     Stance  \n",
              "0  Soldier shot, Parliament locked down after gun...  unrelated  \n",
              "1  Tourist dubbed ‘Spider Man’ after spider burro...  unrelated  \n",
              "2  Luke Somers 'killed in failed rescue attempt i...  unrelated  \n",
              "3   BREAKING: Soldier shot at War Memorial in Ottawa  unrelated  \n",
              "4  Giant 8ft 9in catfish weighing 19 stone caught...  unrelated  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjzVz2ifijmj",
        "colab_type": "text"
      },
      "source": [
        "## Step2: Data Pre-processing and setting some hyper parameters needed for model\n",
        "\n",
        "\n",
        "#### Run the code given below to set the required parameters.\n",
        "\n",
        "1. `MAX_SENTS` = Maximum no.of sentences to consider in an article.\n",
        "\n",
        "2. `MAX_SENT_LENGTH` = Maximum no.of words to consider in a sentence.\n",
        "\n",
        "3. `MAX_NB_WORDS` = Maximum no.of words in the total vocabualry.\n",
        "\n",
        "4. `MAX_SENTS_HEADING` = Maximum no.of sentences to consider in a heading of an article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDXSdpvqjuqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = 20000\n",
        "MAX_SENTS = 20\n",
        "MAX_SENTS_HEADING = 1\n",
        "MAX_SENT_LENGTH = 20\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwE7CPHdiDT-",
        "colab_type": "text"
      },
      "source": [
        "### Download the `Punkt` from nltk using the commands given below. This is for sentence tokenization.\n",
        "\n",
        "For more info on how to use it, read [this](https://stackoverflow.com/questions/35275001/use-of-punktsentencetokenizer-in-nltk).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsiKmyJUZ-hU",
        "colab_type": "code",
        "outputId": "ec9c1613-8899-49a8-bdcb-5688d13ab6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqwm_GbwwnhX",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizing the text and loading the pre-trained Glove word embeddings for each token  [5 marks] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfZLR24mm32k",
        "colab_type": "text"
      },
      "source": [
        "Keras provides [Tokenizer API](https://keras.io/preprocessing/text/) for preparing text. Read it before going any further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLSn9S-5oG4Z",
        "colab_type": "text"
      },
      "source": [
        "#### Import the Tokenizer from keras preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-VUgh2yoMlR",
        "colab_type": "code",
        "outputId": "d4fa8d64-9133-44ae-c34e-c0b56abc41de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eml0Lge4oOuh",
        "colab_type": "text"
      },
      "source": [
        "#### Initialize the Tokenizer class with maximum vocabulary count as `MAX_NB_WORDS` initialized at the start of step2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm85qirPofc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBe1KuXDosJ7",
        "colab_type": "text"
      },
      "source": [
        "#### Now, using fit_on_texts() from Tokenizer class, lets encode the data \n",
        "\n",
        "Note: We need to fit articleBody and Headline also to cover all the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5rk-UyBlmyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(list(train_merge_df['articleBody'] + train_merge_df['Headline']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omptHX-JpBsN",
        "colab_type": "text"
      },
      "source": [
        "#### fit_on_texts() gives the following attributes in the output as given [here](https://faroit.github.io/keras-docs/1.2.2/preprocessing/text/).\n",
        "\n",
        "* **word_counts:** dictionary mapping words (str) to the number of times they appeared on during fit. Only set after fit_on_texts was called.\n",
        "\n",
        "* **word_docs:** dictionary mapping words (str) to the number of documents/texts they appeared on during fit. Only set after fit_on_texts was called.\n",
        "\n",
        "* **word_index:** dictionary mapping words (str) to their rank/index (int). Only set after fit_on_texts was called.\n",
        "\n",
        "* **document_count:** int. Number of documents (texts/sequences) the tokenizer was trained on. Only set after fit_on_texts or fit_on_sequences was called.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHnsT2sTtFAA",
        "colab_type": "text"
      },
      "source": [
        "### Now, tokenize the sentences using nltk sent_tokenize() and encode the sentences with the ids we got form the above `t.word_index`\n",
        "\n",
        "Initialise 2 lists with names `texts` and `articles`.\n",
        "\n",
        "```\n",
        "texts = [] to store text of article as it is.\n",
        "\n",
        "articles = [] split the above text into a list of sentences.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9RhzRoIHUm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_idx = tokenizer.word_index\n",
        "idx_word = tokenizer.index_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ROVOLFDwA0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = []\n",
        "articles = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjVdijVVvQqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fotjkq_GvoqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from nltk.tokenize import word_tokenize\n",
        "# text = \"God is Great! I won a lottery.\"\n",
        "# print(word_tokenize(text))\n",
        "\n",
        "# Output: ['God', 'is', 'Great', '!', 'I', 'won', 'a', 'lottery', '.']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3N8L25qvsQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from nltk.tokenize import sent_tokenize\n",
        "# text = \"God is Great! I won a lottery.\"\n",
        "# print(sent_tokenize(text))\n",
        "\n",
        "# Output: ['God is Great!', 'I won a lottery ']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctEu-d4c4EZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sent_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
        "## now loop over each sentence and tokenize it separately\n",
        "# for sentence in sent_text:\n",
        "#     tokenized_text = nltk.word_tokenize(sentence)\n",
        "#     tagged = nltk.pos_tag(tokenized_text)\n",
        "#     print(tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWYJ8IX5EqpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_merge_df['articleBody'].dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOWhDcK10V2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = train_merge_df['articleBody']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS1NYdob1UYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7fcc9190-85eb-4701-942c-5447491712b8"
      },
      "source": [
        "texts[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A small meteorite crashed into a wooded area in Nicaragua\\'s capital of Managua overnight, the government said Sunday. Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city\\'s airport, the Associated Press reports. \\n\\nGovernment spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\" House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports. \\nMurillo said Nicaragua will ask international experts to help local scientists in understanding what happened.\\n\\nThe crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee. He said it is still not clear if the meteorite disintegrated or was buried.\\n\\nHumberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.\\n\\n\"We have to study it more because it could be ice or rock,\" he said.\\n\\nWilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light. We have to ask if anyone has a photo or something.\"\\n\\nLocal residents reported hearing a loud boom Saturday night, but said they didn\\'t see anything strange in the sky.\\n\\n\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast. We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.\\n\\nThe site of the crater is near Managua\\'s international airport and an air force base. Only journalists from state media were allowed to visit it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wKp29UNGjT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI5VpeGEF8wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_tokenize(text):\n",
        "    if not text:\n",
        "        print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
        "        text = ''\n",
        "    return nltk.sent_tokenize(text)\n",
        "train_merge_df['tokenized_column'] = train_merge_df.articleBody.apply(custom_tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX5xCLER15Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sent_text = nltk.sent_tokenize(texts)\n",
        "articles = train_merge_df['tokenized_column']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UzoBWl0HQCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "53658dac-2afc-441d-b451-97a8556f52f8"
      },
      "source": [
        "articles[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\",\n",
              " \"Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city's airport, the Associated Press reports.\",\n",
              " 'Government spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\"',\n",
              " 'House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports.',\n",
              " 'Murillo said Nicaragua will ask international experts to help local scientists in understanding what happened.',\n",
              " 'The crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee.',\n",
              " 'He said it is still not clear if the meteorite disintegrated or was buried.',\n",
              " 'Humberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.',\n",
              " '\"We have to study it more because it could be ice or rock,\" he said.',\n",
              " 'Wilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light.',\n",
              " 'We have to ask if anyone has a photo or something.\"',\n",
              " \"Local residents reported hearing a loud boom Saturday night, but said they didn't see anything strange in the sky.\",\n",
              " '\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast.',\n",
              " 'We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.',\n",
              " \"The site of the crater is near Managua's international airport and an air force base.\",\n",
              " 'Only journalists from state media were allowed to visit it.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koTVJjoO6P78",
        "colab_type": "text"
      },
      "source": [
        "## Check 2:\n",
        "\n",
        "first element of texts and articles should be as given below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mWBW99p5UW9",
        "colab_type": "code",
        "outputId": "b335efb0-44e3-4ad8-b82b-628625451cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "texts[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A small meteorite crashed into a wooded area in Nicaragua\\'s capital of Managua overnight, the government said Sunday. Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city\\'s airport, the Associated Press reports. \\n\\nGovernment spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\" House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports. \\nMurillo said Nicaragua will ask international experts to help local scientists in understanding what happened.\\n\\nThe crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee. He said it is still not clear if the meteorite disintegrated or was buried.\\n\\nHumberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.\\n\\n\"We have to study it more because it could be ice or rock,\" he said.\\n\\nWilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light. We have to ask if anyone has a photo or something.\"\\n\\nLocal residents reported hearing a loud boom Saturday night, but said they didn\\'t see anything strange in the sky.\\n\\n\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast. We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.\\n\\nThe site of the crater is near Managua\\'s international airport and an air force base. Only journalists from state media were allowed to visit it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtIjO3ht5EKA",
        "colab_type": "code",
        "outputId": "a8b5ea75-2a56-4e54-b327-894c09e5c9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "articles[0]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\",\n",
              " \"Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city's airport, the Associated Press reports.\",\n",
              " 'Government spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\"',\n",
              " 'House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports.',\n",
              " 'Murillo said Nicaragua will ask international experts to help local scientists in understanding what happened.',\n",
              " 'The crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee.',\n",
              " 'He said it is still not clear if the meteorite disintegrated or was buried.',\n",
              " 'Humberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.',\n",
              " '\"We have to study it more because it could be ice or rock,\" he said.',\n",
              " 'Wilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light.',\n",
              " 'We have to ask if anyone has a photo or something.\"',\n",
              " \"Local residents reported hearing a loud boom Saturday night, but said they didn't see anything strange in the sky.\",\n",
              " '\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast.',\n",
              " 'We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.',\n",
              " \"The site of the crater is near Managua's international airport and an air force base.\",\n",
              " 'Only journalists from state media were allowed to visit it.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W28bi2InHwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ff303c5-7e08-4812-b11b-c7d4a3847cc3"
      },
      "source": [
        "len(articles[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM7_cw-SdIXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4fca4ad8-4064-417d-fb12-e301cf4b18cd"
      },
      "source": [
        "articles[0][0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sbrjcJGdPwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aad571da-d560-4421-e5b8-9bda153c6c67"
      },
      "source": [
        "articles[0][1]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city's airport, the Associated Press reports.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zySpcG9tFra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6HdPWBLP2wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = text_to_word_sequence(articles[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71mEigi4QB-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "17224f1e-9057-4329-e98f-41e53c026719"
      },
      "source": [
        "words"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'small',\n",
              " 'meteorite',\n",
              " 'crashed',\n",
              " 'into',\n",
              " 'a',\n",
              " 'wooded',\n",
              " 'area',\n",
              " 'in',\n",
              " \"nicaragua's\",\n",
              " 'capital',\n",
              " 'of',\n",
              " 'managua',\n",
              " 'overnight',\n",
              " 'the',\n",
              " 'government',\n",
              " 'said',\n",
              " 'sunday']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdlgw_F2QLR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_encoding = tokenizer.texts_to_sequences(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xoiBKtsQTiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "2598e6f3-e2b7-4346-baa8-d808aa7d9c04"
      },
      "source": [
        "words_encoding"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3],\n",
              " [485],\n",
              " [433],\n",
              " [7204],\n",
              " [81],\n",
              " [3],\n",
              " [3732],\n",
              " [331],\n",
              " [5],\n",
              " [3888],\n",
              " [350],\n",
              " [4],\n",
              " [1432],\n",
              " [2956],\n",
              " [1],\n",
              " [89],\n",
              " [12],\n",
              " [464]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpuRIA7cCfcY",
        "colab_type": "text"
      },
      "source": [
        "# Now iterate through each article and each sentence to encode the words into ids using t.word_index  [5 marks] \n",
        "\n",
        "Here, to get words from sentence you can use `text_to_word_sequence` from keras preprocessing text.\n",
        "\n",
        "1. Import text_to_word_sequence\n",
        "\n",
        "2. Initialize a variable of shape (no.of articles, MAX_SENTS, MAX_SENT_LENGTH) with name `data` with zeros first (you can use numpy [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html) to initialize with all zeros)and then update it while iterating through the words and sentences in each article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nff5muklKnQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56g2RSaALVOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_row = train_merge_df.shape[0]  # gives number of row count\n",
        "count_col = train_merge_df.shape[1]  # gives number of col count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4DZKUjOivhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb3edadc-f3d4-4751-a6ba-1ea4294a2203"
      },
      "source": [
        "count_row"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spoUO2NFKjeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.zeros((count_row, MAX_SENTS, MAX_SENT_LENGTH), dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G21OQi242sQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e681f534-9175-4773-f1eb-a432bd7b1023"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49972, 20, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-3rxuu-Upm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "1aa5a0fc-3a95-4fb2-b6e5-5681858689ff"
      },
      "source": [
        "data[0][:][:]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52FXRJ4vQ-8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "2de7e3f6-0fd9-44bc-88f6-d065b7af7154"
      },
      "source": [
        "data[0, :, :]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enn8Th5e1jia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d49e421-041c-4899-80aa-52eb13d6f24a"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'to': 2,\n",
              " 'a': 3,\n",
              " 'of': 4,\n",
              " 'in': 5,\n",
              " 'and': 6,\n",
              " 'that': 7,\n",
              " 'is': 8,\n",
              " 'was': 9,\n",
              " 'on': 10,\n",
              " 'for': 11,\n",
              " 'said': 12,\n",
              " 'he': 13,\n",
              " 'with': 14,\n",
              " 'it': 15,\n",
              " 'his': 16,\n",
              " 'have': 17,\n",
              " 'as': 18,\n",
              " 'by': 19,\n",
              " 'has': 20,\n",
              " 'at': 21,\n",
              " 'from': 22,\n",
              " 'be': 23,\n",
              " 'an': 24,\n",
              " 'not': 25,\n",
              " 'are': 26,\n",
              " 'been': 27,\n",
              " 'but': 28,\n",
              " 'who': 29,\n",
              " '”': 30,\n",
              " 'this': 31,\n",
              " 'had': 32,\n",
              " 'they': 33,\n",
              " 'after': 34,\n",
              " 'i': 35,\n",
              " 'were': 36,\n",
              " 'we': 37,\n",
              " 'will': 38,\n",
              " 'about': 39,\n",
              " 'one': 40,\n",
              " 'or': 41,\n",
              " 'isis': 42,\n",
              " 'which': 43,\n",
              " 'video': 44,\n",
              " 'she': 45,\n",
              " 'apple': 46,\n",
              " 'state': 47,\n",
              " 'up': 48,\n",
              " 'her': 49,\n",
              " 'would': 50,\n",
              " 'their': 51,\n",
              " 'more': 52,\n",
              " 'also': 53,\n",
              " 'when': 54,\n",
              " 'told': 55,\n",
              " 'new': 56,\n",
              " 'out': 57,\n",
              " 'no': 58,\n",
              " 'all': 59,\n",
              " 'people': 60,\n",
              " 'there': 61,\n",
              " 'you': 62,\n",
              " 'its': 63,\n",
              " 'if': 64,\n",
              " 'him': 65,\n",
              " 'man': 66,\n",
              " 'news': 67,\n",
              " 'islamic': 68,\n",
              " 'could': 69,\n",
              " 'what': 70,\n",
              " 'year': 71,\n",
              " 'watch': 72,\n",
              " 'time': 73,\n",
              " 'al': 74,\n",
              " 'over': 75,\n",
              " 'some': 76,\n",
              " 'group': 77,\n",
              " 'according': 78,\n",
              " 's': 79,\n",
              " 'u': 80,\n",
              " 'into': 81,\n",
              " 'first': 82,\n",
              " 'so': 83,\n",
              " 'being': 84,\n",
              " 'reports': 85,\n",
              " 'just': 86,\n",
              " 'last': 87,\n",
              " 'syria': 88,\n",
              " 'government': 89,\n",
              " 'police': 90,\n",
              " '—': 91,\n",
              " 'two': 92,\n",
              " 'us': 93,\n",
              " 'them': 94,\n",
              " 'reported': 95,\n",
              " 'kim': 96,\n",
              " 'while': 97,\n",
              " 'any': 98,\n",
              " 'other': 99,\n",
              " 'media': 100,\n",
              " 'like': 101,\n",
              " 'than': 102,\n",
              " 'before': 103,\n",
              " 'then': 104,\n",
              " 'north': 105,\n",
              " 'american': 106,\n",
              " 'can': 107,\n",
              " 'now': 108,\n",
              " 'report': 109,\n",
              " 'says': 110,\n",
              " 'may': 111,\n",
              " 'story': 112,\n",
              " 'foley': 113,\n",
              " 'iraq': 114,\n",
              " 'where': 115,\n",
              " 'my': 116,\n",
              " 'made': 117,\n",
              " 'killed': 118,\n",
              " 'even': 119,\n",
              " 'because': 120,\n",
              " 'against': 121,\n",
              " 'militants': 122,\n",
              " 'do': 123,\n",
              " 'since': 124,\n",
              " 'old': 125,\n",
              " 'only': 126,\n",
              " 'security': 127,\n",
              " 'officials': 128,\n",
              " 'off': 129,\n",
              " 'say': 130,\n",
              " 'our': 131,\n",
              " 'city': 132,\n",
              " 'three': 133,\n",
              " 'years': 134,\n",
              " 'brown': 135,\n",
              " 'border': 136,\n",
              " 'how': 137,\n",
              " 'back': 138,\n",
              " 'during': 139,\n",
              " 'name': 140,\n",
              " 'claims': 141,\n",
              " 'boko': 142,\n",
              " 'another': 143,\n",
              " 'around': 144,\n",
              " '000': 145,\n",
              " 'get': 146,\n",
              " 'jong': 147,\n",
              " 'still': 148,\n",
              " 'official': 149,\n",
              " 'haram': 150,\n",
              " 'through': 151,\n",
              " 'world': 152,\n",
              " 'journalist': 153,\n",
              " 'air': 154,\n",
              " 'leader': 155,\n",
              " 'including': 156,\n",
              " 'under': 157,\n",
              " 'near': 158,\n",
              " 'twitter': 159,\n",
              " \"it's\": 160,\n",
              " 'many': 161,\n",
              " 'family': 162,\n",
              " 'see': 163,\n",
              " 'reportedly': 164,\n",
              " 'did': 165,\n",
              " 'death': 166,\n",
              " 'found': 167,\n",
              " 'week': 168,\n",
              " 'ebola': 169,\n",
              " 'fighters': 170,\n",
              " 'mr': 171,\n",
              " 'military': 172,\n",
              " 'those': 173,\n",
              " 'iraqi': 174,\n",
              " 'confirmed': 175,\n",
              " 'post': 176,\n",
              " 'day': 177,\n",
              " 'girls': 178,\n",
              " 'your': 179,\n",
              " 'however': 180,\n",
              " 'most': 181,\n",
              " 'life': 182,\n",
              " 'british': 183,\n",
              " 'statement': 184,\n",
              " \"'\": 185,\n",
              " 'house': 186,\n",
              " 'michael': 187,\n",
              " 'left': 188,\n",
              " 'obama': 189,\n",
              " 'released': 190,\n",
              " 'going': 191,\n",
              " 'down': 192,\n",
              " 'woman': 193,\n",
              " 'shooting': 194,\n",
              " 'very': 195,\n",
              " '–': 196,\n",
              " 'it’s': 197,\n",
              " 'went': 198,\n",
              " 'service': 199,\n",
              " 'release': 200,\n",
              " 'forces': 201,\n",
              " '2014': 202,\n",
              " 'know': 203,\n",
              " 'known': 204,\n",
              " 'james': 205,\n",
              " 'me': 206,\n",
              " 'month': 207,\n",
              " 'tuesday': 208,\n",
              " 'shot': 209,\n",
              " 'days': 210,\n",
              " 'well': 211,\n",
              " 'missing': 212,\n",
              " 'make': 213,\n",
              " 'least': 214,\n",
              " 'source': 215,\n",
              " 'way': 216,\n",
              " 'these': 217,\n",
              " 'president': 218,\n",
              " 'public': 219,\n",
              " 'kurdish': 220,\n",
              " 'times': 221,\n",
              " 'taken': 222,\n",
              " 'part': 223,\n",
              " 'attack': 224,\n",
              " 'seen': 225,\n",
              " 'next': 226,\n",
              " 'syrian': 227,\n",
              " 'health': 228,\n",
              " 'believed': 229,\n",
              " 'monday': 230,\n",
              " 'later': 231,\n",
              " 'several': 232,\n",
              " 'war': 233,\n",
              " 'company': 234,\n",
              " 'town': 235,\n",
              " 'hospital': 236,\n",
              " 'took': 237,\n",
              " '10': 238,\n",
              " 'information': 239,\n",
              " 'heard': 240,\n",
              " 'posted': 241,\n",
              " 'saying': 242,\n",
              " 'press': 243,\n",
              " 'used': 244,\n",
              " 'six': 245,\n",
              " 'korean': 246,\n",
              " 'intelligence': 247,\n",
              " 'claimed': 248,\n",
              " 'captured': 249,\n",
              " 'photo': 250,\n",
              " 'sources': 251,\n",
              " 'show': 252,\n",
              " 'york': 253,\n",
              " 'son': 254,\n",
              " 'site': 255,\n",
              " 'such': 256,\n",
              " 'un': 257,\n",
              " 'never': 258,\n",
              " 'shots': 259,\n",
              " 'local': 260,\n",
              " 'long': 261,\n",
              " 'home': 262,\n",
              " 'high': 263,\n",
              " 'something': 264,\n",
              " 'john': 265,\n",
              " 'come': 266,\n",
              " 'think': 267,\n",
              " 'much': 268,\n",
              " 'wednesday': 269,\n",
              " 'ago': 270,\n",
              " '12': 271,\n",
              " 'though': 272,\n",
              " 'former': 273,\n",
              " 'both': 274,\n",
              " 'night': 275,\n",
              " 'million': 276,\n",
              " 'added': 277,\n",
              " 'called': 278,\n",
              " 'facebook': 279,\n",
              " 'audio': 280,\n",
              " 'take': 281,\n",
              " 'dead': 282,\n",
              " 'same': 283,\n",
              " 'inside': 284,\n",
              " '2': 285,\n",
              " 'right': 286,\n",
              " 'country': 287,\n",
              " 'officer': 288,\n",
              " 'held': 289,\n",
              " 'number': 290,\n",
              " 'between': 291,\n",
              " 'white': 292,\n",
              " 'office': 293,\n",
              " 'earlier': 294,\n",
              " 'cnn': 295,\n",
              " 'work': 296,\n",
              " 'go': 297,\n",
              " 'father': 298,\n",
              " 'thomas': 299,\n",
              " 'social': 300,\n",
              " 'head': 301,\n",
              " 'online': 302,\n",
              " 'based': 303,\n",
              " 'real': 304,\n",
              " '1': 305,\n",
              " 'recording': 306,\n",
              " 'claim': 307,\n",
              " 'national': 308,\n",
              " 'wilson': 309,\n",
              " 'across': 310,\n",
              " '11': 311,\n",
              " 'kidnapped': 312,\n",
              " 'jobs': 313,\n",
              " 'control': 314,\n",
              " 'set': 315,\n",
              " 'friends': 316,\n",
              " 'use': 317,\n",
              " 'daily': 318,\n",
              " 'spokesman': 319,\n",
              " 'mosul': 320,\n",
              " 'recent': 321,\n",
              " '2012': 322,\n",
              " 'shows': 323,\n",
              " 'korea': 324,\n",
              " 'com': 325,\n",
              " 'yet': 326,\n",
              " 'should': 327,\n",
              " 'militant': 328,\n",
              " 'front': 329,\n",
              " 'person': 330,\n",
              " 'area': 331,\n",
              " 'youtube': 332,\n",
              " 'airstrikes': 333,\n",
              " 'appears': 334,\n",
              " 'past': 335,\n",
              " 'members': 336,\n",
              " 'came': 337,\n",
              " 'put': 338,\n",
              " 'united': 339,\n",
              " 'thought': 340,\n",
              " 'gold': 341,\n",
              " 'london': 342,\n",
              " 'parliament': 343,\n",
              " 'website': 344,\n",
              " '“the': 345,\n",
              " 'states': 346,\n",
              " 'today': 347,\n",
              " 'article': 348,\n",
              " 'died': 349,\n",
              " 'capital': 350,\n",
              " 'international': 351,\n",
              " 'weapons': 352,\n",
              " 'case': 353,\n",
              " 'appeared': 354,\n",
              " 'emwazi': 355,\n",
              " 'might': 356,\n",
              " 'asked': 357,\n",
              " 'street': 358,\n",
              " 'canadian': 359,\n",
              " '2015': 360,\n",
              " 'until': 361,\n",
              " 'fired': 362,\n",
              " 'end': 363,\n",
              " 'alleged': 364,\n",
              " 'months': 365,\n",
              " 'school': 366,\n",
              " 'help': 367,\n",
              " 'south': 368,\n",
              " 'good': 369,\n",
              " 'few': 370,\n",
              " 'four': 371,\n",
              " 'want': 372,\n",
              " 'fact': 373,\n",
              " '“i': 374,\n",
              " 'second': 375,\n",
              " 'whether': 376,\n",
              " 'students': 377,\n",
              " 'away': 378,\n",
              " 'tv': 379,\n",
              " 'working': 380,\n",
              " 'own': 381,\n",
              " 'steve': 382,\n",
              " 'using': 383,\n",
              " 'message': 384,\n",
              " 'god': 385,\n",
              " 'washington': 386,\n",
              " 'again': 387,\n",
              " 'allegedly': 388,\n",
              " 'comment': 389,\n",
              " 'building': 390,\n",
              " 'likely': 391,\n",
              " 'got': 392,\n",
              " '9': 393,\n",
              " 'spider': 394,\n",
              " 'early': 395,\n",
              " 'making': 396,\n",
              " 'hit': 397,\n",
              " 'wrote': 398,\n",
              " 'hoax': 399,\n",
              " 'store': 400,\n",
              " 'each': 401,\n",
              " 'place': 402,\n",
              " 'recently': 403,\n",
              " 'nigerian': 404,\n",
              " 'weeks': 405,\n",
              " 'department': 406,\n",
              " 'find': 407,\n",
              " 'thursday': 408,\n",
              " 'trying': 409,\n",
              " 'announced': 410,\n",
              " 'really': 411,\n",
              " 'car': 412,\n",
              " 'rumors': 413,\n",
              " 'following': 414,\n",
              " '5': 415,\n",
              " 'friday': 416,\n",
              " 'does': 417,\n",
              " 'young': 418,\n",
              " 'five': 419,\n",
              " 'internet': 420,\n",
              " 'coming': 421,\n",
              " 'given': 422,\n",
              " 'attacks': 423,\n",
              " 'hands': 424,\n",
              " 'already': 425,\n",
              " 'september': 426,\n",
              " 'west': 427,\n",
              " 'iphone': 428,\n",
              " 'men': 429,\n",
              " 'august': 430,\n",
              " 'terror': 431,\n",
              " 'identified': 432,\n",
              " 'meteorite': 433,\n",
              " 'lot': 434,\n",
              " 'wife': 435,\n",
              " 'late': 436,\n",
              " '“we': 437,\n",
              " 'women': 438,\n",
              " 'here': 439,\n",
              " 'incident': 440,\n",
              " 'led': 441,\n",
              " 'big': 442,\n",
              " '2011': 443,\n",
              " 'fighting': 444,\n",
              " 'image': 445,\n",
              " '2013': 446,\n",
              " 'true': 447,\n",
              " 'fire': 448,\n",
              " 'airport': 449,\n",
              " 'caught': 450,\n",
              " 'actually': 451,\n",
              " 'videos': 452,\n",
              " 'why': 453,\n",
              " 'texas': 454,\n",
              " 'further': 455,\n",
              " 'comes': 456,\n",
              " 'named': 457,\n",
              " 'baghdadi': 458,\n",
              " 'live': 459,\n",
              " 'fake': 460,\n",
              " 'david': 461,\n",
              " 'reporting': 462,\n",
              " 'newspaper': 463,\n",
              " 'sunday': 464,\n",
              " 'force': 465,\n",
              " 'bale': 466,\n",
              " 'strikes': 467,\n",
              " 'himself': 468,\n",
              " 'apparently': 469,\n",
              " 'whose': 470,\n",
              " 'black': 471,\n",
              " 'outside': 472,\n",
              " 'page': 473,\n",
              " 'among': 474,\n",
              " 'free': 475,\n",
              " 'morning': 476,\n",
              " 'despite': 477,\n",
              " 'marijuana': 478,\n",
              " 'taking': 479,\n",
              " 'director': 480,\n",
              " 'boy': 481,\n",
              " 'terrorist': 482,\n",
              " 'authorities': 483,\n",
              " 'medical': 484,\n",
              " 'small': 485,\n",
              " 'believe': 486,\n",
              " '6': 487,\n",
              " 'friend': 488,\n",
              " 'children': 489,\n",
              " 'film': 490,\n",
              " 'too': 491,\n",
              " 'full': 492,\n",
              " '20': 493,\n",
              " 'happened': 494,\n",
              " 'chief': 495,\n",
              " 'beheading': 496,\n",
              " 'kobani': 497,\n",
              " 'without': 498,\n",
              " 'face': 499,\n",
              " 'rosenberg': 500,\n",
              " 'via': 501,\n",
              " 'islam': 502,\n",
              " 'doctors': 503,\n",
              " 'began': 504,\n",
              " 'food': 505,\n",
              " 'far': 506,\n",
              " 'ottawa': 507,\n",
              " 'body': 508,\n",
              " 'anyone': 509,\n",
              " 'point': 510,\n",
              " 'large': 511,\n",
              " 'amazon': 512,\n",
              " 'account': 513,\n",
              " 'decided': 514,\n",
              " 'confirm': 515,\n",
              " 'close': 516,\n",
              " 'don’t': 517,\n",
              " 'law': 518,\n",
              " 'look': 519,\n",
              " 'ever': 520,\n",
              " 'started': 521,\n",
              " 'co': 522,\n",
              " 'power': 523,\n",
              " 'little': 524,\n",
              " 'possible': 525,\n",
              " 'abu': 526,\n",
              " '100': 527,\n",
              " 'ferguson': 528,\n",
              " 'event': 529,\n",
              " 'saturday': 530,\n",
              " 'western': 531,\n",
              " 'child': 532,\n",
              " 'open': 533,\n",
              " 'born': 534,\n",
              " 'prime': 535,\n",
              " 'revealed': 536,\n",
              " 'mother': 537,\n",
              " 'gave': 538,\n",
              " 'money': 539,\n",
              " 'aid': 540,\n",
              " 'clear': 541,\n",
              " 'details': 542,\n",
              " 'dog': 543,\n",
              " 'nigeria': 544,\n",
              " 'stop': 545,\n",
              " 'device': 546,\n",
              " 'cases': 547,\n",
              " 'hours': 548,\n",
              " 'sure': 549,\n",
              " 'instead': 550,\n",
              " 'arrested': 551,\n",
              " 'become': 552,\n",
              " 'smith': 553,\n",
              " 'daughter': 554,\n",
              " 'associated': 555,\n",
              " 'start': 556,\n",
              " 'play': 557,\n",
              " 'army': 558,\n",
              " 'israeli': 559,\n",
              " 'expected': 560,\n",
              " 'northern': 561,\n",
              " 'due': 562,\n",
              " 'parents': 563,\n",
              " '40': 564,\n",
              " 'enough': 565,\n",
              " 'once': 566,\n",
              " 'thing': 567,\n",
              " 'although': 568,\n",
              " 'showed': 569,\n",
              " 'able': 570,\n",
              " '4': 571,\n",
              " 'violence': 572,\n",
              " 'banksy': 573,\n",
              " 'saw': 574,\n",
              " 'soldiers': 575,\n",
              " 'minister': 576,\n",
              " 'mark': 577,\n",
              " 'interview': 578,\n",
              " 'things': 579,\n",
              " 'pause': 580,\n",
              " 'fight': 581,\n",
              " 'users': 582,\n",
              " 'deal': 583,\n",
              " 'foreign': 584,\n",
              " 'isil': 585,\n",
              " '18': 586,\n",
              " 'secret': 587,\n",
              " 'skin': 588,\n",
              " 'paul': 589,\n",
              " 'human': 590,\n",
              " 'middle': 591,\n",
              " 'ceasefire': 592,\n",
              " 'officers': 593,\n",
              " 'launch': 594,\n",
              " 'macbook': 595,\n",
              " 'turned': 596,\n",
              " '8': 597,\n",
              " 'fbi': 598,\n",
              " 'showing': 599,\n",
              " 'ground': 600,\n",
              " 'star': 601,\n",
              " 'almost': 602,\n",
              " 'de': 603,\n",
              " 'tour': 604,\n",
              " 'role': 605,\n",
              " 'others': 606,\n",
              " 'along': 607,\n",
              " 'order': 608,\n",
              " 'looking': 609,\n",
              " 'probably': 610,\n",
              " 'call': 611,\n",
              " 'behind': 612,\n",
              " 'center': 613,\n",
              " 'pope': 614,\n",
              " 'read': 615,\n",
              " 'investigation': 616,\n",
              " 'ministry': 617,\n",
              " 'give': 618,\n",
              " 'party': 619,\n",
              " 'operation': 620,\n",
              " 'spice': 621,\n",
              " 'having': 622,\n",
              " 'heart': 623,\n",
              " 'agency': 624,\n",
              " 'policy': 625,\n",
              " 'conference': 626,\n",
              " 'change': 627,\n",
              " 'woods': 628,\n",
              " 'libya': 629,\n",
              " 'hostages': 630,\n",
              " 'senior': 631,\n",
              " 'east': 632,\n",
              " 'run': 633,\n",
              " 'bibeau': 634,\n",
              " 'rights': 635,\n",
              " '3': 636,\n",
              " 'comcast': 637,\n",
              " 'homeless': 638,\n",
              " 'immediately': 639,\n",
              " 'holding': 640,\n",
              " 'brother': 641,\n",
              " 'soon': 642,\n",
              " 'april': 643,\n",
              " 'every': 644,\n",
              " 'blumenthal': 645,\n",
              " 'photos': 646,\n",
              " 'centre': 647,\n",
              " 'suspected': 648,\n",
              " 'currently': 649,\n",
              " \"don't\": 650,\n",
              " 'support': 651,\n",
              " 'actor': 652,\n",
              " 'killing': 653,\n",
              " 'murder': 654,\n",
              " 'nothing': 655,\n",
              " 'price': 656,\n",
              " 'hunter': 657,\n",
              " 'terrorists': 658,\n",
              " 'christian': 659,\n",
              " 'decision': 660,\n",
              " 'top': 661,\n",
              " 'november': 662,\n",
              " 'move': 663,\n",
              " '200': 664,\n",
              " 'evidence': 665,\n",
              " 'witnesses': 666,\n",
              " 'am': 667,\n",
              " 'inch': 668,\n",
              " 'follow': 669,\n",
              " 'zehaf': 670,\n",
              " 'level': 671,\n",
              " 'francis': 672,\n",
              " 'sotloff': 673,\n",
              " 'phone': 674,\n",
              " 'schoolgirls': 675,\n",
              " 'names': 676,\n",
              " 'sister': 677,\n",
              " 'kind': 678,\n",
              " 'hand': 679,\n",
              " 'suspect': 680,\n",
              " 'america': 681,\n",
              " 'animals': 682,\n",
              " 'memorial': 683,\n",
              " 'jihadi': 684,\n",
              " 'previously': 685,\n",
              " 'virus': 686,\n",
              " 'water': 687,\n",
              " 'girl': 688,\n",
              " 'talks': 689,\n",
              " 'thousands': 690,\n",
              " 'reuters': 691,\n",
              " '13': 692,\n",
              " 'wanted': 693,\n",
              " 'stolen': 694,\n",
              " 'wright': 695,\n",
              " 'version': 696,\n",
              " 'staff': 697,\n",
              " 'crater': 698,\n",
              " 'major': 699,\n",
              " \"didn't\": 700,\n",
              " 'done': 701,\n",
              " 'attorney': 702,\n",
              " 'google': 703,\n",
              " 'pumpkin': 704,\n",
              " 'hostage': 705,\n",
              " 'january': 706,\n",
              " 'mohammed': 707,\n",
              " 'love': 708,\n",
              " 'tell': 709,\n",
              " 'wearing': 710,\n",
              " 'carried': 711,\n",
              " 'situation': 712,\n",
              " 'uk': 713,\n",
              " 'seems': 714,\n",
              " 'mass': 715,\n",
              " '22': 716,\n",
              " 'need': 717,\n",
              " 'plans': 718,\n",
              " 'trip': 719,\n",
              " 'baby': 720,\n",
              " 'planes': 721,\n",
              " 'movie': 722,\n",
              " 'leave': 723,\n",
              " 'detained': 724,\n",
              " 'lin': 725,\n",
              " 'general': 726,\n",
              " 'continued': 727,\n",
              " 'described': 728,\n",
              " 'spoke': 729,\n",
              " 'campaign': 730,\n",
              " 'images': 731,\n",
              " 'edition': 732,\n",
              " 'soldier': 733,\n",
              " 'condition': 734,\n",
              " 'islamist': 735,\n",
              " 'within': 736,\n",
              " 'must': 737,\n",
              " 'weekend': 738,\n",
              " 'saudi': 739,\n",
              " 'reached': 740,\n",
              " 'contact': 741,\n",
              " 'that’s': 742,\n",
              " 'running': 743,\n",
              " 'mexico': 744,\n",
              " 'didn’t': 745,\n",
              " '30': 746,\n",
              " 'identity': 747,\n",
              " 'rumor': 748,\n",
              " 'october': 749,\n",
              " 'mail': 750,\n",
              " '24': 751,\n",
              " 'organization': 752,\n",
              " 'drug': 753,\n",
              " 'problem': 754,\n",
              " 'female': 755,\n",
              " 'pentagon': 756,\n",
              " 'residents': 757,\n",
              " 'issue': 758,\n",
              " 'someone': 759,\n",
              " 'returned': 760,\n",
              " 'threat': 761,\n",
              " 'getting': 762,\n",
              " 'masked': 763,\n",
              " 'best': 764,\n",
              " 'birth': 765,\n",
              " 'user': 766,\n",
              " 'continue': 767,\n",
              " 'outlets': 768,\n",
              " 'keep': 769,\n",
              " 'different': 770,\n",
              " 'date': 771,\n",
              " 'doing': 772,\n",
              " 'picture': 773,\n",
              " 'living': 774,\n",
              " 'impact': 775,\n",
              " 'earth': 776,\n",
              " 'experts': 777,\n",
              " '7': 778,\n",
              " 'boston': 779,\n",
              " 'johnson': 780,\n",
              " 'action': 781,\n",
              " 'english': 782,\n",
              " '15': 783,\n",
              " 'qaeda': 784,\n",
              " 'related': 785,\n",
              " 'viral': 786,\n",
              " 'remains': 787,\n",
              " 'camera': 788,\n",
              " 'africa': 789,\n",
              " 'extremist': 790,\n",
              " 'important': 791,\n",
              " 'update': 792,\n",
              " 'vice': 793,\n",
              " 'received': 794,\n",
              " 'latest': 795,\n",
              " 'university': 796,\n",
              " 'often': 797,\n",
              " 'gang': 798,\n",
              " 'business': 799,\n",
              " 'authenticity': 800,\n",
              " 'station': 801,\n",
              " 'minutes': 802,\n",
              " 'penis': 803,\n",
              " 'job': 804,\n",
              " 'everything': 805,\n",
              " 'st': 806,\n",
              " 'scotland': 807,\n",
              " 'false': 808,\n",
              " 'february': 809,\n",
              " 'southern': 810,\n",
              " 'vogue': 811,\n",
              " 'pro': 812,\n",
              " 'beheaded': 813,\n",
              " 'private': 814,\n",
              " 'vehicle': 815,\n",
              " 'kobane': 816,\n",
              " 'member': 817,\n",
              " 'meeting': 818,\n",
              " 'footage': 819,\n",
              " 'hill': 820,\n",
              " 'dozens': 821,\n",
              " 'central': 822,\n",
              " 'seven': 823,\n",
              " \"that's\": 824,\n",
              " 'similar': 825,\n",
              " '25': 826,\n",
              " 'sex': 827,\n",
              " 'scene': 828,\n",
              " 'low': 829,\n",
              " 'speaking': 830,\n",
              " 'haines': 831,\n",
              " 'lebanese': 832,\n",
              " 'seized': 833,\n",
              " 'great': 834,\n",
              " 'december': 835,\n",
              " 'claiming': 836,\n",
              " 'suffering': 837,\n",
              " 'nearly': 838,\n",
              " 'caused': 839,\n",
              " 'became': 840,\n",
              " 'services': 841,\n",
              " 'spent': 842,\n",
              " 'quickly': 843,\n",
              " 'steven': 844,\n",
              " 'arms': 845,\n",
              " 'justice': 846,\n",
              " 'court': 847,\n",
              " 'launched': 848,\n",
              " 'dropped': 849,\n",
              " 'aircraft': 850,\n",
              " 'customers': 851,\n",
              " 'spread': 852,\n",
              " 'met': 853,\n",
              " 'network': 854,\n",
              " 'region': 855,\n",
              " 'makes': 856,\n",
              " 'bbc': 857,\n",
              " '14': 858,\n",
              " 'moment': 859,\n",
              " 'alive': 860,\n",
              " 'knew': 861,\n",
              " 'stopped': 862,\n",
              " 'removed': 863,\n",
              " 'main': 864,\n",
              " 'space': 865,\n",
              " 'safe': 866,\n",
              " 'strike': 867,\n",
              " 'march': 868,\n",
              " 'surgery': 869,\n",
              " 'shared': 870,\n",
              " 'yo': 871,\n",
              " 'm': 872,\n",
              " 'age': 873,\n",
              " 'king': 874,\n",
              " 'published': 875,\n",
              " 'market': 876,\n",
              " 'less': 877,\n",
              " 'line': 878,\n",
              " 'comments': 879,\n",
              " 'felt': 880,\n",
              " 'sell': 881,\n",
              " 'game': 882,\n",
              " 'kurds': 883,\n",
              " 'bary': 884,\n",
              " 'arrest': 885,\n",
              " 'abducted': 886,\n",
              " 'josh': 887,\n",
              " 'expert': 888,\n",
              " 'everyone': 889,\n",
              " 'multiple': 890,\n",
              " 'anything': 891,\n",
              " 'lost': 892,\n",
              " 'cut': 893,\n",
              " 'vickers': 894,\n",
              " '31': 895,\n",
              " 'room': 896,\n",
              " 'television': 897,\n",
              " 'tape': 898,\n",
              " 'bakr': 899,\n",
              " 'june': 900,\n",
              " 'jordanian': 901,\n",
              " 'series': 902,\n",
              " 'groups': 903,\n",
              " 'guard': 904,\n",
              " 'instagram': 905,\n",
              " 'lives': 906,\n",
              " 'worker': 907,\n",
              " 'olsen': 908,\n",
              " 'pga': 909,\n",
              " 'apartment': 910,\n",
              " 'gunman': 911,\n",
              " 'batmobile': 912,\n",
              " 'muslims': 913,\n",
              " 'leadership': 914,\n",
              " 'available': 915,\n",
              " 'discovered': 916,\n",
              " 'team': 917,\n",
              " 'fighter': 918,\n",
              " 'culkin': 919,\n",
              " 'either': 920,\n",
              " 'journalists': 921,\n",
              " '“it': 922,\n",
              " 'denied': 923,\n",
              " 'experience': 924,\n",
              " 'pyongyang': 925,\n",
              " 'key': 926,\n",
              " 'nearby': 927,\n",
              " 'fall': 928,\n",
              " 'involved': 929,\n",
              " 'return': 930,\n",
              " 'fox': 931,\n",
              " 'followed': 932,\n",
              " 'capture': 933,\n",
              " 'app': 934,\n",
              " 'web': 935,\n",
              " 'book': 936,\n",
              " 'below': 937,\n",
              " 'tweeted': 938,\n",
              " 'gone': 939,\n",
              " 'sent': 940,\n",
              " 'door': 941,\n",
              " 'symptoms': 942,\n",
              " 'cause': 943,\n",
              " 'charge': 944,\n",
              " 'adding': 945,\n",
              " 'single': 946,\n",
              " 'bit': 947,\n",
              " 'mike': 948,\n",
              " 'somalia': 949,\n",
              " 'pretty': 950,\n",
              " 'leading': 951,\n",
              " 'perhaps': 952,\n",
              " 'offices': 953,\n",
              " 'godane': 954,\n",
              " 'abdel': 955,\n",
              " 'blog': 956,\n",
              " 'cost': 957,\n",
              " \"he's\": 958,\n",
              " 'victims': 959,\n",
              " 'turkey': 960,\n",
              " 'model': 961,\n",
              " 'areas': 962,\n",
              " 'ran': 963,\n",
              " 'jets': 964,\n",
              " 'miles': 965,\n",
              " 'verified': 966,\n",
              " 'sorkin': 967,\n",
              " \"apple's\": 968,\n",
              " 'percent': 969,\n",
              " 'coalition': 970,\n",
              " 'asteroid': 971,\n",
              " 'doesn’t': 972,\n",
              " 'sold': 973,\n",
              " 'side': 974,\n",
              " 'married': 975,\n",
              " 'jihadists': 976,\n",
              " 'appear': 977,\n",
              " 'spokesperson': 978,\n",
              " 'defense': 979,\n",
              " 'jihadist': 980,\n",
              " 'cook': 981,\n",
              " 'duncan': 982,\n",
              " 'magazine': 983,\n",
              " 'americans': 984,\n",
              " 'recorded': 985,\n",
              " \"doesn't\": 986,\n",
              " 'course': 987,\n",
              " 'wintour': 988,\n",
              " 'disease': 989,\n",
              " 'shekau': 990,\n",
              " '’': 991,\n",
              " 'hear': 992,\n",
              " 'israel': 993,\n",
              " 'means': 994,\n",
              " 'priest': 995,\n",
              " 'created': 996,\n",
              " 'hard': 997,\n",
              " '26': 998,\n",
              " 'reporter': 999,\n",
              " 'worked': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJGlHxAo1SrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dd52eec-e8b0-4d6d-be62-94d0ebae1d21"
      },
      "source": [
        "tokenizer.word_index['somalia']"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wNY7bsBz8iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exc = []\n",
        "for i, sentences in enumerate(articles):\n",
        "  for j, sent in enumerate(sentences):\n",
        "    if j < MAX_SENTS:\n",
        "      wordTokens = text_to_word_sequence(sent)\n",
        "      k = 0\n",
        "      for _, word in enumerate(wordTokens):\n",
        "        try:\n",
        "          if k < MAX_SENT_LENGTH and tokenizer.word_index[word] < MAX_NB_WORDS:\n",
        "            data[i, j, k] = tokenizer.word_index[word]\n",
        "            k = k + 1\n",
        "        except:\n",
        "          exc.append(word)\n",
        "          pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMtG2bmI48zZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b238effe-c90e-47cc-90fa-f90387b39b1b"
      },
      "source": [
        "data[0, :, :]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    3,   485,   433,  7204,    81,     3,  3732,   331,     5,\n",
              "         3888,   350,     4,  1432,  2956,     1,    89,    12,   464,\n",
              "            0,     0],\n",
              "       [  757,    95,  1045,     3,  2675,  1750,     7,   188,     3,\n",
              "         1217,  1074,  2026,   698,   158,     1,  3029,   449,     1,\n",
              "          555,   243],\n",
              "       [   89,  1065,  4111,  2345,    12,     3,  1092,  3300,    19,\n",
              "            1,    89,     2,  1791,     1,   529,  2005,    15,     9,\n",
              "            3,  3107],\n",
              "       [  186,  3639,   971,   202,  2553,    43,  6770,  1719,  1250,\n",
              "            5, 13306, 17921,     1,   776,    31,   738,  3986,    67,\n",
              "           85,     0],\n",
              "       [ 2345,    12,  1584,    38,  1094,   351,   777,     2,   367,\n",
              "          260,  1775,     5,  4447,    70,   494,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    1,   698,   188,    19,     1,   433,    32,     3,  7411,\n",
              "            4,  2256,  1250,     6,     3,  5266,     4,  1217,  1250,\n",
              "           12,  3359],\n",
              "       [   13,    12,    15,     8,   148,    25,   541,    64,     1,\n",
              "          433,  3726,    41,     9,  1848,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [ 3359,  5729,     4,     1,  5869,   613,    21,     1,   308,\n",
              "         3432,   796,     4,  1584,    12,     1,   433,    69,    23,\n",
              "          785,     2],\n",
              "       [   37,    17,     2,  1791,    15,    52,   120,    15,    69,\n",
              "           23,  4916,    41,  1960,    13,    12,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [ 4733,  3334,    24,  3965,     2,     1,  1314,     4,  3067,\n",
              "         1651,    12,    15,     9,   195,  1423,     7,    58,    40,\n",
              "           95,     3],\n",
              "       [   37,    17,     2,  1094,    64,   509,    20,     3,   250,\n",
              "           41,   264,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  260,   757,    95,  1045,     3,  1804,  1750,   530,   275,\n",
              "           28,    12,    33,   700,   163,   891,  1423,     5,     1,\n",
              "         2078,     0],\n",
              "       [   35,     9,  2057,    10,   116,  5820,     6,    35,   574,\n",
              "          655,   104,    59,     4,     3,  2407,    35,   240,     3,\n",
              "          511,  1910],\n",
              "       [   37,   340,    15,     9,     3,  2079,   120,    37,   880,\n",
              "           24,  4448,  2581,  4315,  4917,    55,     1,   555,   243,\n",
              "            0,     0],\n",
              "       [    1,   255,     4,     1,   698,     8,   158,  3957,   351,\n",
              "          449,     6,    24,   154,   465,  1926,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  126,   921,    22,    47,   100,    36,  1832,     2,  1212,\n",
              "           15,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vfj5yx_36-R9",
        "colab": {}
      },
      "source": [
        "#words_all = []\n",
        "#data_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AHl5bA3L693A",
        "colab": {}
      },
      "source": [
        "#from keras.preprocessing import text, sequence\n",
        "#from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QAwKL_0e69ZD",
        "colab": {}
      },
      "source": [
        "#for i in range(0, count_row-1):\n",
        "#  for j in range(0, len(articles[i])):\n",
        "#    words_all.append(text_to_word_sequence(articles[i][j]))\n",
        "    #data_list.append(tokenizer.texts_to_sequences(words_all))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KI_H73oD687x",
        "colab": {}
      },
      "source": [
        "#data_list = tokenizer.texts_to_sequences(words_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m6vSY6Gq684s",
        "colab": {}
      },
      "source": [
        "#data_list = sequence.pad_sequences(data_list, maxlen=MAX_SENT_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b44886a6-f1d0-4b76-e4d7-7a7f55326d10",
        "id": "_Dg4HSMA68vc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#data_list.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(816000, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbRsVUNsrRkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1b41662-ea70-4e13-902c-e1bcd82a64ff"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49972, 20, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMS7dlqosZ5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_list_reshape = np.reshape(data_list, (-1, 20, 20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7l4BVJXsk6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e86bd5d3-24a5-4379-e713-681ddac3ffd0"
      },
      "source": [
        "#data_list_reshape.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40800, 20, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmXmBvI8tJ4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data = data_list_reshape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arw2qF79te_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e46c171a-e932-4094-9928-32119c8d069b"
      },
      "source": [
        "#data.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40800, 20, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFdmiDYcE144",
        "colab_type": "text"
      },
      "source": [
        "### Check 3:\n",
        "\n",
        "Accessing first element in data should give something like given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsFWW5C2Djog",
        "colab_type": "code",
        "outputId": "ec1daf8f-1e56-4e3d-b6e3-b40a06c406b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        }
      },
      "source": [
        "data[0, :, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    3,   487,   474,  7113,    79,     3,  3687,   325,     5,\n",
              "         4200,   361,     4,  1525,  2913,     1,    89,    12,   451,\n",
              "            0,     0],\n",
              "       [  743,    96,  1044,     3,  2814,  1759,     7,   186,     3,\n",
              "         1219,  1070,  1987,   736,   154,     1,  2990,   458,     1,\n",
              "          543,   232],\n",
              "       [   89,  1052,  4057,  2314,    12,     3,  1073,  3248,    19,\n",
              "            1,    89,     2,  1751,     1,   518,  1980,    15,     9,\n",
              "            3,  2879],\n",
              "       [  182,  3691,   976,   196,  2515,    42,  6688,  1691,  1227,\n",
              "            5, 13011, 17379,     1,   762,    30,   722,  3931,    66,\n",
              "           87,     0],\n",
              "       [ 2314,    12,  1882,    38,  1076,   346,   793,     2,   356,\n",
              "          261,  1782,     5,  4396,    67,   486,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    1,   736,   186,    19,     1,   474,    32,     3,  7307,\n",
              "            4,  2122,  1227,     6,     3,  5195,     4,  1219,  1227,\n",
              "           12,  3308],\n",
              "       [   13,    12,    15,     8,   143,    25,   531,    63,     1,\n",
              "          474,  3679,    41,     9,  1825,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [ 3308,  5643,     4,     1,  5788,   620,    22,     1,   302,\n",
              "         3125,   786,     4,  1882,    12,     1,   474,    70,    23,\n",
              "          801,     2],\n",
              "       [   35,    17,     2,  1751,    15,    54,   119,    15,    70,\n",
              "           23,  4850,    41,  1885,    13,    12,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [ 4664,  3279,    24,  3915,     2,     1,  1298,     4,  3028,\n",
              "         1630,    12,    15,     9,   187,  1423,     7,    56,    40,\n",
              "           96,     3],\n",
              "       [   35,    17,     2,  1076,    63,   497,    20,     3,   252,\n",
              "           41,   260,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  261,   743,    96,  1044,     3,  1765,  1759,   520,   273,\n",
              "           29,    12,    33,   702,   160,   818,  1423,     5,     1,\n",
              "         2068,     0],\n",
              "       [   34,     9,  2035,    10,   112,  5741,     6,    34,   562,\n",
              "          644,   104,    57,     4,     3,  2382,    34,   238,     3,\n",
              "          504,  1922],\n",
              "       [   35,   341,    15,     9,     3,  2053,   119,    35,   872,\n",
              "           24,  4397,  2541,  4258,  4851,    55,     1,   543,   232,\n",
              "            0,     0],\n",
              "       [    1,   254,     4,     1,   736,     8,   154,  4116,   346,\n",
              "          458,     6,    24,   152,   460,  1908,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  124,   896,    21,    48,   102,    37,  1803,     2,  1195,\n",
              "           15,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTG6JySHehkT",
        "colab_type": "text"
      },
      "source": [
        "# Repeat the same process for the `Headings` as well. Use variables with names `texts_heading` and `articles_heading` accordingly. [5 marks] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV6bdN_oTtPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_heading = []\n",
        "articles_heading = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKFk-XFgT5Ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_merge_df['Headline'].dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwJu9imRUE-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_heading = train_merge_df['Headline']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWAy-OaxUKWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "580ec8fc-d829-434b-ee9b-00190f41a252"
      },
      "source": [
        "texts_heading[0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Soldier shot, Parliament locked down after gunfire erupts at war memorial'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cV_MUdL9Uiij",
        "colab": {}
      },
      "source": [
        "text_heading = texts_heading"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9ney0fzUiim",
        "colab": {}
      },
      "source": [
        "def custom_tokenize(text_heading):\n",
        "    if not text_heading:\n",
        "        print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
        "        text_heading = ''\n",
        "    return nltk.sent_tokenize(text_heading)\n",
        "train_merge_df['tokenized_heading_column'] = train_merge_df.Headline.apply(custom_tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YmY2E3jwUiio",
        "colab": {}
      },
      "source": [
        "# sent_text = nltk.sent_tokenize(texts)\n",
        "articles_heading = train_merge_df['tokenized_heading_column']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYMX8QEz9dQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4ba03dc-27db-48fe-cd55-cb459fdcd7c8"
      },
      "source": [
        "articles_heading"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [Soldier shot, Parliament locked down after gu...\n",
              "1        [Tourist dubbed ‘Spider Man’ after spider burr...\n",
              "2        [Luke Somers 'killed in failed rescue attempt ...\n",
              "3        [BREAKING: Soldier shot at War Memorial in Ott...\n",
              "4        [Giant 8ft 9in catfish weighing 19 stone caugh...\n",
              "5        [Enormous 20-stone catfish caught with fishing...\n",
              "6        [Italian catches huge wels catfish; is it a re...\n",
              "7        [Not coming to a store near you: The pumpkin s...\n",
              "8        [One gunman killed in shooting on Parliament H...\n",
              "9                 [Soldier shot at war memorial in Canada]\n",
              "10       [Surreal Photos of Fisherman’s Jaw-Dropping Ca...\n",
              "11       [Fisherman lands 19 STONE catfish which could ...\n",
              "12         [Source: Tom Brokaw Wants Brian Williams Fired]\n",
              "13       [A soldier has been shot at Canada’s war memor...\n",
              "14       [280 Pound Catfish: Fisherman Makes Huge Catch...\n",
              "15       [Rumor debunked: RoboCop-style robots are not ...\n",
              "16       [Caught a catfish record in Po: 127 kg and 2.6...\n",
              "17       [Monster catfish which looks big enough to swa...\n",
              "18       [Luke Somers' sister says he was killed in fai...\n",
              "19       [Apple Watch to Be Shower-Proof, Have 100,000 ...\n",
              "20        [Soldier shot near Canadian parliament building]\n",
              "21                [Soldier shot in Ottawa at War Memorial]\n",
              "22       [Soldier shot at War Memorial; multiple shots ...\n",
              "23       [Comcast Is Threatening To Cut Off Customers W...\n",
              "24       [Small Meteorite Strikes in Nicaragua's Capita...\n",
              "25       [Breaking: Soldier shot at National War Memori...\n",
              "26       [Google to buy big chunk of Pacific Shores, ic...\n",
              "27       [Canadian Soldier Shot At Ottawa War Memorial:...\n",
              "28       [Iraqi social-media rumors claim IS leader slain]\n",
              "29       [There has been a shooting at the War Memorial...\n",
              "                               ...                        \n",
              "49942    [20 year old burger?, McDonald's burger purcha...\n",
              "49943    [Jihadi John: Mohammed Emwazi named as masked ...\n",
              "49944      [Mum Offers to Sell Twin Boy to Save Twin Girl]\n",
              "49945    [Shocking picture shows mother trying to sell ...\n",
              "49946    [ISIS Militant “Jihadi John” Identified As You...\n",
              "49947    [ISIS Executioner 'Jihadi John' Is Named as Mo...\n",
              "49948    [Would you take a bite out of the world's olde...\n",
              "49949    [#Hairgate: iPhone 6 users say device pulls ou...\n",
              "49950    [That ESPN Domestic Violence Panel You Keep He...\n",
              "49951    [Jihadi John UNMASKED: Islamic State killer NA...\n",
              "49952    [Bergdahl: Senator Says Jihadists Swapped For ...\n",
              "49953    [Man Known as ‘Jihadi John’ Is Identified as M...\n",
              "49954    [Report: Taliban Detainee Swapped for Bowe Ber...\n",
              "49955    [Taliban member swapped by Obama for Bowe Berg...\n",
              "49956    [Is this the world's oldest burger?, Man claim...\n",
              "49957    [No, ESPN is not having an all-male domestic v...\n",
              "49958    [There was never a panel discussion on domesti...\n",
              "49959      [ISIS executioner 'Jihadi John' named by media]\n",
              "49960                              [World's oldest burger]\n",
              "49961    [Is this the world's oldest burger?, Man claim...\n",
              "49962    [Official: Gitmo prisoner traded for Bergdahl ...\n",
              "49963    [Is Kim Jong-Un Really Opening a Restaurant in...\n",
              "49964    [ESPN to save NFL's image with all-male domest...\n",
              "49965    [Guantanamo detainee who was swapped in prison...\n",
              "49966    [Pizza delivery driver surprised with $2,000 tip]\n",
              "49967    [Pizza delivery man gets tipped more than $2,0...\n",
              "49968                 [Pizza delivery man gets $2,000 tip]\n",
              "49969    [Luckiest Pizza Delivery Guy Ever Gets $2,000 ...\n",
              "49970    [Ann Arbor pizza delivery driver surprised wit...\n",
              "49971    [Ann Arbor pizza delivery driver surprised wit...\n",
              "Name: tokenized_heading_column, Length: 49972, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3b45ca09-a0d9-4fde-edf8-882cb86db908",
        "id": "H8Lqvo-jUiis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "articles_heading[0]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Soldier shot, Parliament locked down after gunfire erupts at war memorial']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qFki_25Raibf",
        "colab": {}
      },
      "source": [
        "data_heading = np.zeros((len(texts),MAX_SENTS, MAX_SENT_LENGTH),dtype='int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "48b8a347-72bc-4562-ce19-70d559bf3313",
        "id": "45ysabMdaibt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_heading.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49972, 20, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0-rG-3kIaib8",
        "colab": {}
      },
      "source": [
        "exc1 = []\n",
        "for i, sentences in enumerate(articles_heading):\n",
        "  for j, sent in enumerate(sentences):\n",
        "    if j < MAX_SENTS:\n",
        "      wordTokens = text_to_word_sequence(sent)\n",
        "      k = 0\n",
        "      for _, word in enumerate(wordTokens):\n",
        "        try:\n",
        "          if k < MAX_SENT_LENGTH and tokenizer.word_index[word] < MAX_NB_WORDS:\n",
        "            data_heading[i, j, k] = tokenizer.word_index[word]\n",
        "            k = k + 1\n",
        "        except:\n",
        "          exc1.append(word)\n",
        "          pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "28129dfd-2b5d-4675-a56c-a4aa5e7aff0f",
        "id": "MqTp09CjaicQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_heading.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49972, 20, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaH0Ey1qe_Co",
        "colab_type": "text"
      },
      "source": [
        "### Now the features are ready, lets make the labels ready for the model to process.\n",
        "\n",
        "### Convert labels into one-hot vectors\n",
        "\n",
        "You can use [get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) in pandas to create one-hot vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq-VcgM8fat1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = pd.get_dummies(train_merge_df['Stance'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgDxn11l98ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "12585fa6-6490-40ca-b8d2-d0a0ea865bda"
      },
      "source": [
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of data heading tensor:', data_heading.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (49972, 20, 20)\n",
            "Shape of data heading tensor: (49972, 20, 20)\n",
            "Shape of label tensor: (49972, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40mA8FI2fcxZ",
        "colab_type": "text"
      },
      "source": [
        "### Check 4:\n",
        "\n",
        "The shape of data and labels shoould match the given below numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpEWEnjFfnFR",
        "colab_type": "code",
        "outputId": "312006c9-6dff-4704-978e-d08131b483c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (49972, 20, 20)\n",
            "Shape of label tensor: (49972, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDOxHdR3frDu",
        "colab_type": "text"
      },
      "source": [
        "### Shuffle the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ2pcR4G-oVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "60ff96bf-3ab7-4468-ab83-b19093d99070"
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agree</th>\n",
              "      <th>disagree</th>\n",
              "      <th>discuss</th>\n",
              "      <th>unrelated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   agree  disagree  discuss  unrelated\n",
              "0      0         0        0          1\n",
              "1      0         0        0          1\n",
              "2      0         0        0          1\n",
              "3      0         0        0          1\n",
              "4      0         0        0          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbvgcQxH-t8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "7e76fddc-666d-480a-e638-00baa52070b0"
      },
      "source": [
        "labels.values"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 0, 1],\n",
              "       ...,\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVkTE-YX-xU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = labels.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ra-yYTvfzRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## get numbers upto no.of articles\n",
        "indices = np.arange(data.shape[0])\n",
        "## shuffle the numbers\n",
        "np.random.shuffle(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKnSqwIFf3Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## shuffle the data\n",
        "data = data[indices]\n",
        "data_heading = data_heading[indices]\n",
        "## shuffle the labels according to data\n",
        "labels = labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcOFVfPBf9kA",
        "colab_type": "text"
      },
      "source": [
        "### Split into train and validation sets. Split the train set 80:20 ratio to get the train and validation sets.\n",
        "\n",
        "\n",
        "Use the variable names as given below:\n",
        "\n",
        "x_train, x_val - for body of articles.\n",
        "\n",
        "x-heading_train, x_heading_val - for heading of articles.\n",
        "\n",
        "y_train - for training labels.\n",
        "\n",
        "y_val - for validation labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDJc2L-pGp04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae843f1d-9bcd-47fc-c6ac-f23d97189c9a"
      },
      "source": [
        "data.shape[0]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5SSVmp1Gtg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48b33931-0fb5-42d1-9847-0c87f8dd3fb1"
      },
      "source": [
        "49972*.2"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9994.400000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Q0qr72aCp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data + data_heading"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zpOJ2oxaGyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2neh9Wcof8iR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = data[:-9994]\n",
        "x_val = data[-9994:]\n",
        "y_train = labels[:-9994]\n",
        "y_val = labels[-9994:]\n",
        "x_heading_train = data_heading[:-9994]\n",
        "x_heading_val = data_heading[-9994:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5u3PTz3gEV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ebc0f552-9110-4f18-e719-f3002bbb5aa7"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39978, 20, 20)\n",
            "(39978, 4)\n",
            "(9994, 20, 20)\n",
            "(9994, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTyvoHrsgMDw",
        "colab_type": "text"
      },
      "source": [
        "### Check 5:\n",
        "\n",
        "The shape of x_train, x_val, y_train and y_val should match the below numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLEbiw2Yghe2",
        "colab_type": "code",
        "outputId": "e2390c42-fcda-4165-ae0e-52bd515d8b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39978, 20, 20)\n",
            "(39978, 4)\n",
            "(9994, 20, 20)\n",
            "(9994, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNnoBtArhJ1E",
        "colab_type": "text"
      },
      "source": [
        "### Create embedding matrix with the glove embeddings\n",
        "\n",
        "\n",
        "Run the below code to create embedding_matrix which has all the words and their glove embedding if present in glove word list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKqn2IL2ZF8v",
        "colab_type": "code",
        "outputId": "81e74e01-6d31-49c5-ab6c-c61ef677fff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('./glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRi4o3ZspDFU",
        "colab_type": "text"
      },
      "source": [
        "# Try the sequential model approach and report the accuracy score. [10 marks]  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSZDnPWkw2ZZ",
        "colab_type": "text"
      },
      "source": [
        "### Import layers from Keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AgwQsfMrzAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Embedding, LSTM, Bidirectional\n",
        "from keras import Input, Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpkVhIbx3gr1",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_8QXh-rmPFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74b6ef7f-050c-449c-df97-6c12e5c1981a"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBWQYc5XNNnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGehEwzFNQPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e12f55f0-3ee6-481d-d979-8d8b5768a407"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39978, 400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3-PauqBNYTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.reshape(y_train, (y_train.shape[0], 1, y_train.shape[1]))\n",
        "y_val = np.reshape(y_val, (y_val.shape[0], 1, y_val.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKDxoREsNaCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2dfe7c91-77f3-4f7c-c507-56ec924ecb2c"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39978, 1, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ29PujcID-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "394b672e-1c2c-47b9-d974-2f00b42ca818"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocab_size, output_dim = 100, weights=[embedding_matrix]))\n",
        "model.add(Bidirectional (LSTM (100, return_sequences = True , dropout = 0.2, recurrent_dropout = 0.2), merge_mode='concat'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(4,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 100)         3364200   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, None, 200)         160800    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, None, 64)          12864     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, None, 4)           260       \n",
            "=================================================================\n",
            "Total params: 3,538,124\n",
            "Trainable params: 3,538,124\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Xrd-JQ3id7",
        "colab_type": "text"
      },
      "source": [
        "### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlduHU2CovxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "541f1637-930b-42ac-c8a5-6b75ba35d76b"
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_val, y_val))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 39978 samples, validate on 9994 samples\n",
            "Epoch 1/1\n",
            "39978/39978 [==============================] - 1945s 49ms/step - loss: 0.7444 - acc: 0.7366 - val_loss: 0.6578 - val_acc: 0.7662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc700430208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM3yCmjQoCM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R47A6Ysfev3l",
        "colab_type": "text"
      },
      "source": [
        "## Build the same model with attention layers included for better performance (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ3TWuiAe1Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wivJ-eVkfEOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olqo5ytRe7eq",
        "colab_type": "text"
      },
      "source": [
        "## Fit the model and report the accuracy score for the model with attention layer (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zgxPrhzfBkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8507P94fDuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}